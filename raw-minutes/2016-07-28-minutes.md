
# W3C TAG Minutes: Stockholm 2016-07-28

Scribe: mnot

Present: Peter, Dan, Hadley, Alex, Yves, Travis, David, Andrew, mnot
Absent: Timbl

## Agenda Bashing
https://github.com/w3ctag/meetings/blob/gh-pages/2016/07-stockholm/agenda.md

## IETF Update
mnot: IETF in Berlin last week. 3 different BOFs of interest to the TAG: LURK to allow CDNs to serve SSL content without having the keys. It moves the key negotiation to the customer.
mnot: It turns the key negotiation into an RPC. Akamai, Cloudflare have specs. Issue is that it allows the CDN to talk on behalf of the customer in a "trusted" way, as there are no context on signing.
mnot: You implicitely trust your CDN, but the spec also raised interest in the telco industry. In some places, trusting operators might not be true. This raised concerns.
[discussion on apps, trust model and VPNs]
mnot: QUIC BOF (aka NOT TCP/2) was successful; very smooth. 
mnot: QUIC is a massive undertaking; security, transport, and appliction in the same layer...many people are used to working in a layered fashion, and this smushes them together.
hadley: what risks come with this? What benefits?
mnot: efficency; major efficiency gains.
<3rd bof?>
mnot: PLUS, nee SPUD. UDP protocols are coming and everything is going to be encrypted soon. That makes some people soon. Middlebox vendors (people deploying boxes inside networks to, e.g., inspect flows and manage traffic) made a proposal to adorn UDP-based protocols with metadata. That ensures that only some sorts of metadata can be added to the packets. This would let you say, e.g., that this is the beginning or end of a flow.
ekr: it'd be integrity protected but not encrypted
hadley: what does encryption + UDP do to deep-packet-inspection?
mnot: when you're using encryption (e.g. DTLS), you can build DPI the same way you inspect TLS but it'll require new software. Nothing really changes except for inconvenience.
mnot: so PLUS folks wanted to adorn these things with metadata; e.g. "we'll block all traffic unless it comes with user identifiers".
mnot: waiting on IESG to weigh in
<discussion of other groups that met>
mnot: web push should be close to done.
mnot: discussion about HTTP headers extension rules, including json-based syntax and binary encoding.
mnot: JFE; how to parse and validate headers
mnot: Cache Digest: the ability for the client to tell the server what's in cache so server can reason about it. Need more data about it.
mnot: continuing to revise the cookie spec. There's some early discussion about cookies that live longer than a session on an insecure session.
alex: work started on new cookie API for use inside service workers (etc. etc.): https://github.com/bsittler/async-cookies-api/
dka: are cookies a powerful feature?
mnot: we need to consider this in terms of pervasive monitoring guidance
dka: perhaps we should consider that like a spec review?
mnot: martin has a draft called "eat cookies", will file a bug w/ pointer https://tools.ietf.org/html/draft-thomson-http-omnomnom-00
mnot: ongoing discussion about how to add certificates to an ongoing connection in HTTP. The idea is "I want to do client auth, so I want to add a client cert" which you can't do in H/2 today. But what if I also want to add a new server cert so, e.g., a CDN can handle mutliple origins on the same connection. Lots of excitement about this.
hadley: implications for the same origin policy?
mnot: possibility for some understanding of user's state; lots of questions about that.
mnot: there was BOF about blind-caching, but we can talk about that later as we have EKR here.

## keygen

ekr: it's going away. We're turning it off. Google is turning it off. No specific plans from us, but it's gone.
ekr: I haven't heard anyone in control of browsers saying othewise
hadley: who is us?
ekr: mozilla
travis: what about the client certificate statement? [ http://w3ctag.github.io/client-certificates/ ]
ekr: all the enthusiasm / energy I see is going into WebAuth
travis: that's my impression as well
ekr: there's no interest in re-building keygen, or something involving client certs or other forms of cross-origin key material
ekr: from the perspective of the browsers, it's fortunate that it's such a terrible API, because we can remove it
ekr: but even if it was a good api, we'd still remove it because of the cross-origin keying.
dan: channelling tim -- one key element was the notion that the browser can generate the key pairs, and the private key is unavailable to the app
ekr: fido has that property and more
peter: fido doesn't give you a key that works across origins
alex and ekr: that's a feature, not a bug
alex: this brings up the question of eTLD and conveniece for fido (already have an issue)
peter: people will still want it
ekr: who wants it?
peter: google
alex: no, we only want etld + 1
peter: historically, there are a lot of hosting services that only provide TLS on one domain
alex: this would only apply to TLS connections; can't use fido without it
dan: about our document, it's a draft. Should we amend it?
travis: we do need to integrate webauth.
dan: we need to obsolete this or add information.
mnot: maybe obsolete and start a new, short doc?
alex: principle is that we support auth that doesn't violate user privacy; tim doesn't agree.
dan: I think tim would agree.
alex: but multi-origin is a super-cookie.
ekr: my sense is that keygen was designed in an environment where people expected to have universal identites, attested by certificates. That's obviously not the way that the situation has emerged; besides Facebook connect, we barely have any universal identity at all. The inapplicability of keygen is evidence of this. All identity is now local. [ekr ekrs]
ekr: the browsers are not interested in maintaining keygen, and we think webauth is the way forward. Keys might be generated in some other way.
peter: it looks like there's discussion in webauth about government-based identity, so they are interested in universal id.
ekr: that would be compatible with the design of webauth.
alex: it also embodies a different property, in that it involves user consent at time of use
peter: so do client certs; it's just that the UI is horrible. But, I make the choice of what cert I present to the server. These aren't fundamental tech issues.
ekr: but we have no idea how to address those issues; we haven't made much effort, but there isn't any clear way to make them better.

PROPOSED: amend Keygen document to point to Web Authentication work and publish as a note; start work on a new finding on general authentication arch principles.

travis: looking at the document, there are a lot of issues about it. now that we have webauth, we could refer to it, and take a harder stance about the future.
peter: I don't think anyone is pro-keygen; there are people who are pro-client certs.
travis: webauth still gives you client-based auth, but not origin spanning.
peter: client certs don't have to be, they just can be.
ekr: We're not planning on deprecating TLS client authentication, or its UI.

[client certs doc](https://w3ctag.github.io/client-certificates/)

hadley: possible architecture angles to this:
- a web platform feature being deprecated
- principles for authentication
- If you’re using client certs to authenticate, then do them this way…?
travis: platform features being deprecated doesn't seem to be something we can add to
dan: one of the things the current doc does is put the tag's stamp of approval on deprecating kegen. that's why I support the notion of revising this doc.
david: maybe we should stick to talking about the problems in keygen, and less about what to replace it with
[general]: agreed
dan: right now, we have informative references to webcrypto, serviceworkers, powerful features; should we have an informative ref to webauth
ekr: webauth is more related than web crypto
ekr: attack scenarios are different, because js can change
dan: david, can you make recommendations about what to remove?
david: can try
travis: Here's the issue to put your thoughts: https://github.com/w3ctag/client-certificates/issues/19
dan: overall action is to align the document with reality
dan: other point is whether we need principles of authentication
hadley: I think we do, but I'm concious we may not have the expertise
dan: hadley, can you work on such a document?
ekr: but the properties experts want for an authentication system (privacy-preserving, federated,c
 ...) might not succeed from a business perspective, as we've seen

dan: outcomes -- revise the current document to align with reality, and publish a new document about authentication principles.

## WebRTC

ekr: let me start from the beginning: it's a peer-to-peer communication system. It'd be nice to have data flow directly between clients. We use ICE for that. ICE gathers all possible addresses you'll need to communicate (local, public, relay server) and you spam all of this to the control channel and everyone spams each other to initialize a connection. You send UDP datagrams to all of the addresses you have access to. This gives you the best chance of getting a known connection.
ekr: every WebRTC connection should complete and chance of getting a direct connection are 90-95%. A UDP path to a server is 90-93%; that's QUIC data. This is very important if you want to have good A/V perf. Somtimes this falls back to TCP and that gets you poor perf.
ekr: when WebRTC was designed, the privacy issue was assumed to be about camera/mic issue. There's a permission dialog with varying degrees of persistence.
ekr: WebRTC also has a peer-to-peer data channel which doesn't have any UI associated with it. A game on the LAN, e.g.. No privacy UI. Not sure what that UI would look like even if we wanted one.
ekr: we weren't unaware of this, but there are privacy considerations. They relate to the address gathering function.
ekr: this creates 3 categories of privacy problem. First you can get the local address, even if they're behind a NAT, which you otherwise could not have gotten. That generally only has modest entropy because most NATs assign from a small set of blocks. They also tend not to assign randomly. There's no persistence between mutliple NATs, so you can't track across NATs. It can let you see long DHCP leases. Some of this is also discoverable from script in other ways.
ekr: sometimes people have NATs that are public addresses and WebRTC exposes these.
ekr: there are 2 other cases; web proxies and VPNs. There are multiple sorts of VPNs. Some do a very good job of not exposing your local address. There are a lot of badly designed VPNs. Lots of papers about how to exfiltrate this information. The final part of the privacy story is that there is now data that some sites DO use this for some sort of tracking purpose. A recent paper by <can't recall> shows many people being tracked this way. The most famous is the NYT issue. Wasn't tracking per sae; was anti-fraud from Dan Kaminsky's group (WhiteOps).
ekr: some WebRTC stacks expose another persistent identifier: the DTLS fingerprint. This is per-origin. FF randomizes per connection. 
ekr: many people are upset about these privacy properties. We've opted not to do what people have asked: simply asking for permission before doing anything WebRTC related.
ekr: first, this would make many apps hard to build. Second, we don't know how to ask "do you want to have your local IP address exposed?" in ways users will understand. Won't prompt users when consent is meaningless.
dka: can we ask users if they want to make a peer-to-peer connection?
alex: what's "peer-to-peer"?
ekr: this would look like a security check, which it isn't. A privacy impact instead.
ekr: also, why can't we ask when on a VPN?
ekr: 2 cases: sometihng like TOR-lite vs. internal to a private network (in an office, e.g.) where you don't want to route publicly.
ekr: what browsers have opted to do and what IETF recommends is this: 4 new modes:
    1.) this is the no-permissions-check mode. This is a bit more subtle. We inspect the route to the internet. Then collect the apparent default local address. Only exfilrate that address. That gives you STUN or TURN through that single interface. Not perfect but greatly limits the set of exfiltrated addresses. Used for data channel. Largely addresses drive-by gathering of a VPN-hidden public IP address. Minimizes fingerprint, but not intended to avoid NAT disambiguation. Compromise.
    2.) the current mode. Exfiltrate all addresses. The gateway to this mode is some sort of user consent; generally connected to the camera/mic permission. This stops drive-by's. 
    3.) only exfiltrate publicly visible addresses; do #1 and stun checks. Hides internal private addresses. Disadvantage - higher probability of not being able to connect to people on the same LAN [ requires plugin]. 
    4.) can't remember what this is, but [ requires plugin]
ekr: we do nothing about web proxies. At some point in the future, we may allow user-installed TURN proxies. Those might well override address exfiltration strategies.
ekr: that is the state of play. This has not made anyone particularly happy; implementers are unhappy about user experience impact, privacy people are unhappy too. It's a compromise.
dan: is this documented?
[dka: this is in line with our TAG recommendations from last year: https://www.w3.org/2001/tag/doc/unsanctioned-tracking/]
ekr: Yes, it's an I-D: https://tools.ietf.org/html/draft-ietf-rtcweb-ip-handling-01
[Issue 14 closed]

## QUIC

[introductions]

[Jana's presentation]()

## Event/Meeting Planning

<discussion: voting on how to vote; then voting (also, voting)>

RESOLVED: Meeting the week of Oct 31st in Tokyo (thank you FT!)

<discussion: event planning>

RESOLVED: likely to do a half-day at the end of the scheduled meetings

## HTTP Workshop Update

mnot: many attendees from diverse set of companies and projects. Organised to help keep the community up to date; particularly folks who can't go to all of the standards meetings. 3 days, purposfully unstructured.
mnot: some data from Mozilla on deployment, Cloudflare, Google talked about QUIC, AnneVK from Mozilla talked about fetch(), many lightning talks <scribe fail>
mnot: summary will be published soon.
hadley: output...anything?
mnot: not a decision making body; a community gathering, so no outcomes but many people got together

<discussion>

## WICG discussion

<marcosc and cwilso join>

marcos: things are good! Lots of new proposals are coming through, many from Google. We've been at this about a year, and some proposals are maturing. Directory upload, Intersection Observer, and a few others.
alex: interventions
marcos: had some discussions around that; a bit stalled. Things were going to DOM, but then Anne put it in WHATWG DOM spec. Weren't sure what to do. Would be good to find a solution.
alex: WebUSB, IndexedDB observers...
marcos: WebUSB has some security concerns.
alex: BackgroundSync and Content Performance Policy are active
marcos: what do you want to do with Background Sync?
alex: it seems like there's something to do here about defining when an incubation is complete. E.g., Web Payments left a bit too early.
marcos: yeah, it didn't follow our process; no "intent-to-transition" was sent. The chairs weren't involved there.
cwilso: the W3C kicked off a new process to start a working group that had overlap. There was a lot of pressure to do something there.
cwilso: an incubation is more baked when you're comfortable resolving remaining issues with a clock ticking
hadley: how can we help?
<discussion about when to engage>
plinss: we want to engage early enough to be useful but don't want to step on toes
cwilso: no matter how mature an incubation is, when a WG gets spun up you don't have to go with the incubation outputs. Can go in different directions. The hope is that when we do an intent-to-transition there won't be a ton of changes. Maybe having a TAG review before you intent-to-transition seems like a good marker.
plinss: I was thinking that something like that might help you do gatekeeping to avoid spinning up WGs when things might transition prematurely otherwise
marcos: that happened without us
dbaron: a lot of that happened out in another CG
plinss: maybe it's appropriate for us to take a role in the transition process?
travis: I like the idea of us getting involved even earlier than a transition. We like to get involved and informed in the community. Maybe we can channel that into new work and influence the designs and APIs from the very beginning. Maybe we can take new ideas and then hand them off to others who want to drive them?
marcos: that sounds great. Turns out people are actually reading specs. At least here, people are actually reading these shorter, lighter specs. By all means and you find a model that works, we'd love to have that brought in. We'd love more feedback and would like to learn how to evangelise better.
marcos: doing standards is hard work, as we know
travis: one of the promises of WICG is less process; makes it easier for anyone to engage.
marcos: I think we'll get there. We saw that with responsive images, you need to get ideas rolling. For example with element queries, we've been handling that in a few different ways. Intersection Observers, e.g.. We may not be seeing a groundswell because there's less frustration? Maybe I'm being naive.
marcos: Mozilla's pitching very hard on PWAs, Service Workers, etc. Google and MSFT are doing the same. Maybe we've passed a tipping point...people are experimenting with tons of new stuff...streams, sync, etc. Gave a talk today and 100 people in the room and nobody had implemented Push. A lot of this stuff is new and once people start playing with it we'll find the mistakes, but I think we're at an interesting place in time in the history of the web.
<blaming Alex for things>
marcos: here in Sydney, people seem very excited
mnot: AUS suits you well, mate.
dka: not sure if it's directly related, but to echo some of your exhuberance, at the Google PWA Summit a few weeks ago there were 700 developers. The excitement level was _really high_. I was presenting on behalf of Samsung and we also and Microsoft, Mozilla, Opera, and Samsung and the message came through very clearly that this is a cross-browser thing. I came away with a very positive outlook on that toolbox.
travis: I have a question about some of the ideas that get started in WICG; particularly those that don't come from browser vendors. How are those going?
marcos: a lot of the time we've found that there are frequently other ways to fill the gaps. E.g., "do we need a <geo> element?" and we can use Web Components or something like that. One had a lot of potential was img-conversion. That was about converting between image elements without needing to go through <canvas>. We pitched it inside Mozilla and couldn't get resources, so dropped the ball. We could still pick it up again. Would be tremendously useful.
alex: is there something missing there? A way to raise this stuff with browser vendors?
marcos: I see lots of browser folks involved in the Discourse instance. Tab, Domenic, etc. I watch thigns and so does Yoav, but would love to see more MSFT involvement.
travis: I get a weekly report now and so I've been seeing some of these threads, but it's interesting to see that it's happening. I'm wondering if I need to participate directly in those conversations.
travis: I wonder if it's valuable for me to help promote things that don't have a corrolary that's already in the platform?
marcos: I think that would really help.
travis: should the TAG participate?
marcos: would love that
dka: how?
<discussion of the WICG weekly digest; could it go to one of our aliases?>

<how can we help?>
marcos: we thought WebUSB was really exciting, but Mozilla's security people said "no way". I'm sure Google won't do this if there wasn't a reasonable model. Maybe something the TAG could look at an weigh in on. That's one thing you could weigh in on.
marcos: the other ones are running pretty smoothly. A new one is web sharing; Mozilla folks working with Google folks and maybe something interesting to keep an eye on. We're trying to do an explainer and then get that out to potential users (Twitter, FB) to see if they're interested to see if it's something they might use.
traivs: Anne was doing something about bulk DOM operations...is anything happening there?
marcos: I think that was Yehuda, not Anne. Not sure where that ended up.
alex: there was work on our team about asyncAppend();, something that can chunk up work.
marcos: a lot of things we saw about that area that are about DOM diffing
travis: we can just start things in the Discourse then?
marcos: yes; unless there's an existing repo and then you can point there.

travis: do you have a favorite WICG spec?
cwilso: they're all my favorites
andrew: I started a thing called "content passes" but it didn't go anywhere. I wonder if the current process is set up to help existing spec people find a wider audience but isn't great at helping poeple find a community who are new to it.
marcos: I think that's one of our failings. We should be doing a better job at finding the right people to bring into these projects.
<discussion about how engagement should work>
cwilso: there has to be significant momentum behind anything that goes towards REC. What happens, e.g., if there's no browser vendor involved?
cwilso: the challenging piece between having good ideas rise naturally vs. a thousand proposals for new HTML tags. We do want to allow things to fail fast.
cwilso: without people seeing things and offering to collaborate, things should probably die on the vine. Getting visibility is a challeng, though.
travis: you mentioned that the process is sort of geared towards advertising things that have momentum. Are you tracking these things? How do things percolate toward the top?
marcos: I go through and look for interesting things. I see what gets update, but it's a manual process
cwilso: in terms of watching what's going on, seeing where threads score is the best way to see what's active. We haven't done a good job of putting  bow on things that are really stale. Most of the repos that we have are active in one way or another. The stalest thing was img-conversion and that had an update in Sept last year.
<discussion of discovery>
marcos: things that have repos have made a big step. There are other areas where things were proposed but then taken over, e.g., but the CSS WG. That's success but in a difrerent way
marcos: the only thing I've been doing is to mark things like the payments repos as "historical"
marcos: please look at the repos; make reviewing them a TAG action.
yves: do you think it'd be good to have informative documents? E.g., for when Streams show up?
marcos: guess we should wait for that to happen? The current model -- focusing on specs -- seems to be working. The documents we've got today have been tremendously helpful.
yves: if you identify areas where something like that would help, let us know.
marcos: will do.
<discussion of what's next>

# Webusb sidebar with EKR 

ekr: webusb spec allows - annoying choice of: devices say only my origin can talk to me or allowing arbitrary origins to talk to devices which seems untenable.
alex:
erk: [someone's] paper named icu
... attack - are the lights on the mac cameras hardwired. Turns out they're not. so if you can talk usb to it you can turn off the light [privacy issue]
alex: first issue is affirmitive access control - allowing this origin to talk to me - eg. for http resources...
ekr: I'm unconvinced this an important feature.
alex: there's a huge impact of mozilla saying it's a huge security risk
dka: what are the use cases?
alex: Bluetooth is more my priority
ekr: intuition users think they have - that they're given access to the speaker, camera, ect... unless things are carefully maintained they are actually given access to the whole computer.
…I don't think that the origin lockin thing... reason we have to have CORS is that XHR has ambient authority... Were those things not true then we might not need [CORS]
alex: in TAG we worked on a packaging format - part of the motivation was to have signed packages which could be attested to by multiple parties - like FFOS app model - could have more exotic permissions, or outside of origin policy...
… so - what is the set of capabilities we could open up now that would give us the toe-hold to next capabilities? 
ekr: origin locking functionality in CORS ... unfortunate state of affairs and not optimal.
alex: I agree but I think it's worth doing
ekr:  options for web bluetooth
		1) permission based model
		2) "web bluetooth" device but multiple origins
		3) origin lockin a-la cors
		4) require some kind of add-on
…I think 1 and 3 are quite bad 
Travis: presumably most devices can be accessed through other ways - e.g. getusermedia
ekr: percisely - through a safe way
Travis: raspberry pi connection [is an example of something that can't]
Alex: or 3d printer
ekr: these things have bad security stories - these allow for you to upload new firmware to them... it means that access to these devices is control of your computer...
Hadley: what would you prefer?
ekr: I don't have a problem with USB but it is mediated by the operating system... you're proposing to unmediated [with the webbluetooth API]
…My concern: i write a JS application - I convince you to run it – 
Alex: the counter-factual is downloading a binary onto the computer which can do the same thing.
DKA: OSs dont allow people to download binaries as easily
Travis: the solution for filesystem has been to virtualize it...
[DKA: I think we should come back to this] ***
ekr: [don't think you can do it]
… this “i speak webusb" might be OK.
Alex: access control allow origin * is … ?
ekr: mozilla is not working the software side of this because it's not a prioriity. We have done a preliminary analysis and find it concerning. That's where we stand.
Alex: do you think there's a position in the middle?
ekr: no sane way to prompt a user about this...
Alex: what we're doing with bluetooth is to allow users to select a device - "oh I want it to talk to that thing"
ekr: bluetooth is perhaps better than USB....
… my assumption is that any device that can become any other device -- is a vulnerability. … least powerful devices … I have least confidence of security … if a bluetooth headset can become a keyboard then that's bad.
… uncontroled firmware update … by totally unpublished mechanisms … don't feel allowing the user to give permissions is valid – not sure how to address that unless the device indicates it's prepared to accept that
… kind of data.
Hadley: what worries me - i'm for protecting users - there's a much bigger rights access being granted – I'm also concerned about as we're setting standards we don't want to enshrine bad practices - i worry about
… us saying the web can't go there (ever) because right now we're not ready.
Alex: for bluetooth the solution is to only allow less exploitable messages … set of things you can do is less [potentially harmful]
ekr: We did WebSockets and CORS -- there was a 'first do no harm' attitude here. We thought we couldn't make things more hazardous.  Look at hte masking in web sockets.  I agree we shouldn't enshrine problems in our specs, but...
Alex: … legisltation something something … 
Mnot: to me the summary is : the web enjoys the state of isolation - iot and devices are in for pain for forseeable future …
ekr: low quality devices … device consent model … manufacturers will this on … locked to manufacturer … 
Hadley: we could recommend regulation - "the web is only going to be safe if devices are going to behave in this way" - we could say that we only accept a subset of the USB spec… 
[discussion on this comparative to webmidi]
dka: A specific use case... integrating the physical web so that you get your TV, turn on our TV, it broadcasts a URL over bluetooth as a beacon, that's picked up on your phone, your phone goes to a web page and pulls down a web app that uses the webbluetooth API to control the TV.  The one security aspect that's interesting to me: can the fact that you received the original URL from a webbluetooth hardware address mean you skip over the pairing? So it's a seamless experience for the end user?
ekr: I don't know enough about bluetooth pairing.
dka: Normally, you see a list of devices, tap on that...
ekr: There is a code because there is a radio environment, right? 
plinss: you don't always needthe code with bluetooth
ekr:  How many bluetooth transmitters in this room?  The whole story about autodiscovery of networking devices due to physical proximity — is just a disaster.  I can send you what a wrote for the HTTP workshop.  tl;dr: the situation is terrible.  If you put me in a position where there is a device physically near me, and I want to radio into it, there are 2-3 technologies which are awful.  Once you've logged in, at least you can have continuity. AT Mozilla, we're looking at this over DNS.  Re bluetooth, I'll be interested to see where this goes.  I don't know what the status of the work is... I wasn't planning on sending mean comments.  If we get to the point where Firefox is looking at implementing it, I'm going to be pretty skeptical.  Right now, we are in a 'shrink' phase, going more back to basics.  That will probably give some time before we focus on this.  From a security perspective, strictly speaking, lock in to a vendor is better than nothing.
alex: right now, most devices say "if you want to talk to us, download our possibly-untrustworthy software".  And you do have to trust it.
david: though you make an explicit decision to download it.
alex: so the scale here is putting the user in the mindset of understanding how scary this is. It's not a technical difference.
ekr: sandboxed access to this would be better, I agree.
dka: therefore, shouldn't we as the web community, be thinking more about virtualised services? a gps API, a 3d printer API, etc. So we can escape these issues?
kr: Yes, and that's what we discussed for webRTC.  But that puts us incredibly far behind the native app story, because you need a specific API for each new device
ekr: yes but features … speed of access to new types of devices … range of fetaures available …
… if we can come up with a story about how to tell the user what's going on here then it would [be good]

[tinfoil hat discussion]

alex: idea of giving up some capabilities in order to get other capabiliies [e.g. give up network access to be able to use the usb ...]

#wicg coda

Andrew: I went through WICG theads in Discourse and in many cases they just trail off...
Travis: some are marked as obsolete
Andrews: yes some are locked with a finalcomment - if that can be done as a matter of course that would [be good]… that would give [more context to people who dip in and out]
… maybe for threads that have trailed off, a note [signpost] telling where the discussion has gone o
travis: In Web Platform tests repo, they've noticed when I left stuff off.  GitHub is different.
Hadley: should we do anything with this?
andrew:  Feedback to the WICG?
alex: sounds good.









