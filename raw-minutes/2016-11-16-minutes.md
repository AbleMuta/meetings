TAG call
16 Nov 2016

Attending: Peter, Alex, Andrew, Hadley, David, Yves, Travis, Tim

1.  Polyfill doc
https://docs.google.com/document/d/1u9VgjkPFBgaZE_4xeNCqgF-YReedkTfgXn1WRwmdGFU   

Andrew: [Reviews comments on the Google doc]
... Re def of polyfill... I'm considering it broadly. Anything even if not on standards track, but might be a feature of the web platform... David's point is that is too broad. 

Alex: In Tokyo, we centred on the idea that when there are implementations in the world, it's different. But that speculative script thing — that's less a polyfill and more a hope, or a proprietary addition.

Andrew: Yes, this is the prollyfill case.  That's where the problems happen.  
... For example, if someone is talking about a documentReady promise, and someone writes a feature for it but it isn't in any spec, we'd want to have an opinion on it.

David: My comments in the doc were written in a certain order. I felt there were a bunch of issues about what we're recommending  there might be a tipping point.  Do you defer to native implementations? Do you use the name or some other name?  If there is a single tipping point that changes multiple things, then maybe good to include more before the tipping point.

Andrew: Right.  Tried to clarify how to define the tipping point. Many features that reach CR may not have multiple implementations but do have a stable set of features. I've put in text to describe how polyfill authors could investigate whether a feature has achieved that consensus yet.

Travis: I'm reading those steps... Assertion is that if you're a CR, then you've achieved the tipping point. If not, have multiple browsers implemented it? That's fuzzy consensus.

David: I'm not sure CR alone is good enough. Sometimes it's there to get implementation feedback.

Travis: so that shouldn't be the point?

Hadley: would PR be more useful? When you have to have implementations?

David: PR is definitely safe. CR is likely safe.

Alex: You'd be looking for multiple in-flight implementations.  (The commitment is there.)  Or a test suite.

Travis: Is that enough?

Andrew: Consensus seems here that implemenations are the strongest signal. I'm thikning of grid and flexbox though, which don't fit.  It's not the safest indicator.

Peter: In those cases, you have one implemenation leading the pack.  Then changes were made in the design before there were multiple implemenations.

Alex:  Those are situations where a naive end developer would not be worse off.  You do have multiple implemenations of something like gradients, for example.  The developer who used a polyfill to support that — their users wouldn't be further out to dry.  Same risk profile.  (Also, if everyone supports the thing, you wouldn't need a polyfill.)

Andrew: I like the idea of a cascade of decision points. Is that fair or should we just list some signals and leave it up to them?

Alex: I think we want to call out the point at which you're on the wrong side.

Travis: I'm concerned if we over-constrain it, we'll be wrong and the doc won't be useful. 

Hadley: That sounds sensible. Hard to articulate, but sensible.

Andrew: Okay.  

David: Part of the value of implementations is being able to test that the polyfill and the implementation are matching each other. 

Andrew:  I'd agree.  The fact that a browser is intending to implement something doesn't make it more or less valuable to have a polyfill for it. 
... How to understand the stability of a polyfill?  If it has a test suite, how performant it is, danger signs that it's not performant... what indicators would you look for? 

Travis:  Understanding how many hooks in the platform were required to accomplish the polyfill's goal?  Thinking about an API that has to hook the shadow DOM web components polyfill has to hook untold nuber of APIs to cover all the ways you can create an element. If there are a lot of those type of hooks, either means the polyfill is being very thorough OR it has to do a lot of work to fill its role.  Performance implications.
...Can be dififcult to evaluate without code introspection.  Provide it in metadata.

Andrew: We'd have to recommend to polyfill authors to include that.

Alex: Can we come up with a check-list for those self-assessments?  Is there a visible metric of maturity as part of the Polyfill Service?

Andrew: we have a page of documentation on polyfill.io that indicates size, performance and popularity.  Those are the indicators we're using to decide whether to ship it by default. https://polyfill.io/v2/docs/features/

Travis: Size is also an interesting metric.  Might be a red herring though, because you may be trying to polyfill something that just inherently is complex.  But it might help you compare two competing polyfills to fill the same feature.  The only way to be sure is an algorithmic or run-time analysis...

Andrew: I created JS Manners http://jsmanners.com/ at the FT. I wanted ability to go through a checklist to figure out if this should be stuff to add to a page or not. Gives you a grade. 

Alex: Yeah, that's the kind of weighting and checklist approach I thought might be helpful.

Andrew: There's a lot here then. 

Alex: A non-normative strawman. 

Peter: And something that could be independently updated.

Andrew: A list of conditions in the finding then. 
[Thumbs up from Alex]

...Those are the specific points. Let's discuss the text of the doc on a future call.

David: The one other thing: I wanted to see how it ended.  Last draft, they were just headlines.

Andrew: I've asked others for feedback.  Let's come back in a couple weeks.

2.  Evergreen web finding

David: As of yesterday, it hadn't changed since Tokyo f2f.

Hadley: I think it could use some editorial tidying.  I'll do that and come back with it.

3.  Web VR

Alex: We went through it from the perspective of the DOM, catalogued a bunch of issues.  There are some oddities in the API surface and the model is a bit odd.https://github.com/w3ctag/spec-reviews/blob/master/2016/11/webvr.md 
...Submitframe is weird. There are two capture modes: one is how it works now on the canvas.  SubmitFrame is different; lets you after the last raf and before this one is done, lets you draw and say "i'm ready", but it doesn't change the mode.  It's been added for when you draw a scene to the canvas for VR and you want to display it as well... but it's odd.
...Also resetPose
...But my big concern is how this is going to work on high refresh rates.  Currently it works on the main thread, but if something is going to jank that main thread... won't work.  It'll demo well though.  
...Location of some of the APIs is weird. Working on it.
...Would appreciate feedback from the TAG.

Travis: do they have input requirements outside of what's availalbe on the thread?

Alex: Not really.  One API where they do the C++ thing (getFrameData) — you pass in an object, and it fills the properties of the object even though it's js and has no internal typing.  We have parallel GC technology... It feels micro-optimised.
...You get pose data. That's represented on the VR object.  For this to work, you have to get your input without delay... or you'll feel sick.

Peter: Or fall over.  I think there was a separate issue on that getFrameData question.

Alex: If they want the bring-your-own-buffer thing...  we've just reviewed streamed.  Make it an array buffer and pass that, as opposed to a js object.  

Travis: Is there an option for a requestAnimationFrame variant, put in a high res mode?  Maybe a timer mechanism specific to webVR?

Alex:  The system has VR layers (you create), canvases, and the VR display object.  I'm not sure how this works with the main frame.

Travis:  just becasue most things are 60 frames per sec now... doesn't mean the future won't be 300.  I don't want to bake in an assumption of refresh rates.

Alex: It feels like you wnat a canvas fused to the VR display. 

4

